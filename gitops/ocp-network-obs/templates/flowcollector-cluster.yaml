{{- if .Values.flowCollector.enabled }}
---
apiVersion: flows.netobserv.io/v1beta2
kind: FlowCollector
metadata:
  name: cluster
  annotations:
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    argocd.argoproj.io/sync-wave: "5"
spec:
  namespace: netobserv
  # https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/network_observability/index#network-observability-deploy-network-policy_network_observability
  networkPolicy:
    enable: {{ .Values.networkPolicy.enabled }}
    additionalNamespaces:
      - openshift-console
      - openshift-monitoring
      - kafka
  deploymentModel: {{ .Values.flowCollector.deploymentModel }}
  agent:
    ebpf:
      logLevel: info
      metrics:
        server:
          tls:
            insecureSkipVerify: false
            type: Disabled
      cacheMaxFlows: 100000
      # Privileged mode required for: UDNMapping, PacketDrop, NetworkEvents
      # https://issues.redhat.com/browse/NETOBSERV-2268
      # privileged: {{ or .Values.ebpfFeatures.udnMapping .Values.ebpfFeatures.packetDrop .Values.ebpfFeatures.networkEvents }}
      # https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/network_observability/index#network-observability-dns-tracking_nw-observe-network-traffic
      features:
        {{- if .Values.ebpfFeatures.dnsTracking }}
        - DNSTracking
        {{- end }}
        {{- if .Values.ebpfFeatures.flowRTT }}
        - FlowRTT
        {{- end }}
        {{- if .Values.ebpfFeatures.packetDrop }}
        - PacketDrop
        {{- end }}
        {{- if .Values.ebpfFeatures.networkEvents }}
        - NetworkEvents
        {{- end }}
        {{- if .Values.ebpfFeatures.udnMapping }}
        - UDNMapping
        {{- end }}
        {{- if .Values.ebpfFeatures.packetTranslation }}
        - PacketTranslation
        {{- end }}
        {{- if .Values.ebpfFeatures.ebpfManager }}
        - EbpfManager
        {{- end }}
      sampling: 50
      imagePullPolicy: IfNotPresent
      excludeInterfaces:
        - lo
      {{- if eq .Values.flowCollector.deploymentModel "Kafka" }}
      kafkaBatchSize: {{ .Values.flowCollector.kafkaBatchSize }}
      {{- end }}
      cacheActiveTimeout: 5s
  processor:
    logLevel: info
    resources:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 800Mi
    logTypes: Flows
    multiClusterDeployment: true
    advanced:
      conversationEndTimeout: 10s
      conversationHeartbeatInterval: 30s
  loki:
    enable: {{ .Values.loki.enabled }}
    mode: {{ .Values.loki.mode | quote }}
  prometheus:
    querier:
      enable: true
      mode: Auto
      timeout: 30s
  consolePlugin:
    logLevel: info
    advanced:
      port: 9001
      register: true
    enable: true
    portNaming:
      enable: true
    # https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/network_observability/index#network-observability-config-quick-filters_network_observability
    quickFilters:
      - default: true
        filter:
          flow_layer: '"app"'
        name: Applications
      - filter:
          flow_layer: '"infra"'
        name: Infrastructure
      - default: true
        filter:
          dst_kind: '"Pod"'
          src_kind: '"Pod"'
        name: Pods network
      - filter:
          dst_kind: '"Service"'
        name: Services network
    imagePullPolicy: IfNotPresent
    autoscaler:
      maxReplicas: 3
      metrics:
        - resource:
            target:
              averageUtilization: 50
              type: Utilization
            name: cpu
          type: Resource
      minReplicas: 1
      status: Disabled
    replicas: 1
  {{- if and .Values.kafkaExporter ( .Values.kafkaExporter.enabled ) }}
  exporters:
    - type: Kafka
      kafka:
        address: "{{ .Values.kafkaExporter.serviceName }}.{{ .Values.kafkaExporter.namespace }}:{{ .Values.kafkaExporter.port }}"
        topic: {{ .Values.kafkaExporter.topic | quote }}
        sasl:
          # Type of SASL authentication to use, or Disabled if SASL is not used
          type: ScramSHA512
          clientIDReference:
            type: secret
            name: kafka-sasl-username
            namespace: kafka
            file: username
          clientSecretReference:
            type: secret
            file: password
            name: {{ .Values.kafkaExporter.username }}
            namespace: kafka
        tls:
          enable: true
          insecureSkipVerify: true
  #   - type: OpenTelemetry
  #       openTelemetry:
  #         targetHost: my-otelcol-collector-headless.otlp.svc
  #         targetPort: 4317
  #         type: grpc
  #         logs:
  #           enable: true
  #         metrics:
  #           enable: true
  #           prefix: netobserv
  #           pushTimeInterval: 20s
  #           expiryTime: 2m
  {{- else }}
  exporters: []
  {{- end }}
{{- end }}
